defaults:
  - _self_
  - augmentations: supervised_symmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "kl-pd-distillation-imagenet"
data:
  dataset: imagenet_subset
  n_data: 128117
  train_path: "/mnt/qb/akata/shared/ffcv_imagenet100/train_500_0.50_90.ffcv"
  val_path: "/mnt/qb/akata/shared/ffcv_imagenet100/val_500_0.50_90.ffcv"
  format: "ffcv"
  num_workers: 9
precache: True
ffcv_augmentation: 'default'
ffcv_dtype: 'float16'

loss:
  name: 'xekl_mt'
  alpha: 1
  kd_T: 1
  k: 1000
  gamma: 1
  strat: 'most-conf'
  tau: None
  N: None

optimizer:
  name: "SGD"
  batch_size: 'auto'
  lr: 0.0001
  weight_decay: 1e-4
  momentum: 0.9

scheduler:
  name: None
  warmup: 0

checkpoint:
  enabled: True
  dir: "/mnt/qb/akata/aoq877/trained_models/trained_models"
  frequency: 1

search_id: None
student_id: 1
teacher_id: 2

on_flip:
  pos: 'distill'
  neg: 'distill'
  neut: 'distill'

# overwrite PL stuff
max_epochs: 20
devices: [0]
sync_batchnorm: True
accelerator: "gpu"
strategy: "dp"
precision: 16
seed: 123